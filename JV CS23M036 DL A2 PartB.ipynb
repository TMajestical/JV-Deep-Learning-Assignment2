{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1712312222189,
     "user": {
      "displayName": "Tejasvi",
      "userId": "11432105167454296241"
     },
     "user_tz": -330
    },
    "id": "wUL9xFf2bONI"
   },
   "outputs": [],
   "source": [
    "#JV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fm4TBfAMbONJ"
   },
   "source": [
    "I would develop the code for the assignment in this notebook as it is easy to quickly test (and even unit testing).\n",
    "\n",
    "When a module/part is bug free I would add it to the .py file later.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17667,
     "status": "ok",
     "timestamp": 1712312239854,
     "user": {
      "displayName": "Tejasvi",
      "userId": "11432105167454296241"
     },
     "user_tz": -330
    },
    "id": "vkys2pbsbONK",
    "outputId": "3b1a00ac-9c64-4def-dac7-72837eaac189"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import wandb\n",
    "\n",
    "import torch.optim as optims\n",
    "from torch.utils.data import Dataset, DataLoader,ChainDataset, ConcatDataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1712312239854,
     "user": {
      "displayName": "Tejasvi",
      "userId": "11432105167454296241"
     },
     "user_tz": -330
    },
    "id": "Bj55olkabONK"
   },
   "outputs": [],
   "source": [
    "seed = 76 #setting this as seed wherever randomness comes\n",
    "\n",
    "torch.manual_seed(seed)s\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 95009,
     "status": "ok",
     "timestamp": 1712312334861,
     "user": {
      "displayName": "Tejasvi",
      "userId": "11432105167454296241"
     },
     "user_tz": -330
    },
    "id": "x3Ae-D70bONK",
    "outputId": "518a043f-97d7-4581-e451-3b3824f3ea5d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1712312334861,
     "user": {
      "displayName": "Tejasvi",
      "userId": "11432105167454296241"
     },
     "user_tz": -330
    },
    "id": "JlwFg6d_bONK"
   },
   "outputs": [],
   "source": [
    "class DataPreparation:\n",
    "\n",
    "    def __init__(self,data_dir,device,default_transforms=None):\n",
    "\n",
    "        self.base_dir  = data_dir\n",
    "        self.device = device\n",
    "        self.default_transforms = default_transforms\n",
    "\n",
    "\n",
    "    def create_dataloader(self,sub_dir,batch_size=16,shuffle=True,num_workers=2,data_augmentation_transforms = None,pin_memory = False):\n",
    "\n",
    "        \"\"\"\n",
    "        Method to create dataset and return dataloader after applying all necessary transforms.\n",
    "\n",
    "        params:\n",
    "\n",
    "            sub_dir : \"train/\" or \"validation/\" or \"test/\"\n",
    "            batch_size : The batch size in which training has to be performed.\n",
    "            shuffle : whether shuffling must be done before sampling.\n",
    "            num_works : Number of workers to be used on the dataset.\n",
    "            data_augmentation_transforms : Either None or List of List of transforms, with each sub-list leading to a dataset.\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            Dataloader corresponding to the dataset.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"Preparing data from {sub_dir}\")\n",
    "\n",
    "\n",
    "        ## The most basic list of transforms applied to the orignal train dataset and validation and test dataset.\n",
    "        vanilla_transforms = [self.default_transforms]\n",
    "\n",
    "        if (\"train\" in sub_dir) and (data_augmentation_transforms): ## if data augmentation is to be done\n",
    "\n",
    "            original_dataset = torchvision.datasets.ImageFolder(root=self.base_dir+sub_dir,transform=transforms.Compose(vanilla_transforms))\n",
    "\n",
    "            dataset_list = [original_dataset]\n",
    "\n",
    "            for aug_transform in data_augmentation_transforms:\n",
    "\n",
    "                cur_data_transforms_list = [self.default_transforms] + aug_transform\n",
    "                cur_dataset = torchvision.datasets.ImageFolder(root=self.base_dir+sub_dir,transform=transforms.Compose(cur_data_transforms_list))\n",
    "                dataset_list.append(cur_dataset)\n",
    "\n",
    "            self.dataset = ConcatDataset(dataset_list)\n",
    "        else:\n",
    "\n",
    "            self.dataset = torchvision.datasets.ImageFolder(root=self.base_dir+sub_dir,transform=transforms.Compose(vanilla_transforms))\n",
    "\n",
    "\n",
    "\n",
    "        ## Now create the data loader\n",
    "\n",
    "        sampler = None ## unless the dataloading is distributed across devices or processes.\n",
    "\n",
    "        if \"train\" in sub_dir:\n",
    "\n",
    "            #torch.distributed.init_process_group(rank=0,world_size = 4)\n",
    "\n",
    "            #sampler = DistributedSampler(self.dataset)\n",
    "\n",
    "            self.loader = torch.utils.data.DataLoader(dataset=self.dataset,batch_size=batch_size,shuffle=shuffle,num_workers=num_workers,pin_memory = pin_memory,sampler=sampler)\n",
    "\n",
    "        else:\n",
    "\n",
    "            num_workers = 3\n",
    "            pin_memory = False\n",
    "\n",
    "            self.loader = torch.utils.data.DataLoader(self.dataset,batch_size=batch_size,shuffle=False,num_workers=num_workers,pin_memory = pin_memory,sampler=sampler)\n",
    "\n",
    "        return self.loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1712312334861,
     "user": {
      "displayName": "Tejasvi",
      "userId": "11432105167454296241"
     },
     "user_tz": -330
    },
    "id": "VAiaTeOvbONK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1712312334861,
     "user": {
      "displayName": "Tejasvi",
      "userId": "11432105167454296241"
     },
     "user_tz": -330
    },
    "id": "qoz2QVnIbONK"
   },
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "\n",
    "    \"\"\"\n",
    "    Class to create and conduct experiments\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,device,base_dir,wandb_logging=False,on_kaggle = False):\n",
    "\n",
    "        self.device = device\n",
    "        self.base_data_dir = base_dir\n",
    "        self.wandb_logging = wandb_logging\n",
    "        self.on_kaggle = on_kaggle\n",
    "\n",
    "    def create_dataloaders(self,batch_size,shuffle,list_of_train_data_augmentation_transforms,num_workers=0,pin_memory=False):\n",
    "\n",
    "        \"\"\"\n",
    "        Method to create dataloaders for train,test and validation datasets, with the help from the DataPreparation class.\n",
    "\n",
    "        params:\n",
    "\n",
    "            batch_size : The training batch size (also applied to test and validation loaders, but anyway its still the same).\n",
    "            shuffle : True/False, whether to shuffle data before sampling.\n",
    "            list_of_train_data_augmentation_transforms : None, if no data augmentation or List of List of transforms, with each sub-list leading to a dataset.\n",
    "            num_workers : Number of workers to support the dataloader, default is 0.\n",
    "            pin_memory : Default is False. Pinning memory makes data loading efficent when a accelerator is used and num of workers>0.\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            Torch dataloader objects for training,testing and validation data.\n",
    "\n",
    "        \"\"\"\n",
    "        ## Create an object of the data preparation class\n",
    "        dataprep = DataPreparation(data_dir=self.base_data_dir,device = self.device,default_transforms = self.default_transforms)\n",
    "\n",
    "        if (not self.device == \"cpu\") and num_workers>0:\n",
    "            pin_memory = True\n",
    "\n",
    "        ## create a train dataset loader\n",
    "        self.train_loader = dataprep.create_dataloader(sub_dir = \"train/\",batch_size = batch_size,shuffle = shuffle, num_workers = num_workers,data_augmentation_transforms = list_of_train_data_augmentation_transforms,pin_memory=pin_memory)\n",
    "\n",
    "        ## it is not efficient to pin memory for validation and test datasets,as they are relatively small.\n",
    "        self.val_loader = dataprep.create_dataloader(sub_dir = \"validation/\",batch_size = batch_size,shuffle = shuffle, num_workers = num_workers,pin_memory=False)\n",
    "        self.test_loader = dataprep.create_dataloader(sub_dir = \"test/\",batch_size = batch_size,shuffle = shuffle, num_workers = num_workers,pin_memory=False)\n",
    "\n",
    "        return self.train_loader,self.val_loader,self.test_loader\n",
    "\n",
    "\n",
    "    def createResNet(self,num_output_neurons):\n",
    "\n",
    "        \"\"\"\n",
    "        Method to Create the ResNet architecture with the pre-trained weights. Making suitable for finetuning.\n",
    "\n",
    "        Params:\n",
    "\n",
    "            num_output_neurons: Number of neurons in the output layer.\n",
    "\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            None.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2) ##using weights of IMAGENET1K_V2, which gave an accuracy of 80%\n",
    "\n",
    "        weights = ResNet50_Weights.IMAGENET1K_V2\n",
    "        self.default_transforms = weights.transforms() ## these are the transforms to be applied on the input images before feeding to the model\n",
    "\n",
    "        # Freeze all layers except the last layer\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        ## Now the output layer of ResNet50 model simply passes through the output of the penultimate hidden layer.\n",
    "        ## last fully connected layer of resnet can be accessed using model.fc\n",
    "\n",
    "        resnet_last_fc_size = self.model.fc.in_features ## first store the output size.\n",
    "        self.model.fc = nn.Identity()\n",
    "\n",
    "        ## now add an output layer with 10 neurons to ResNet50 model\n",
    "        self.model.fc = nn.Linear(resnet_last_fc_size, out_features=num_output_neurons)\n",
    "\n",
    "        ## Initializae weights and biases of this layer. Using xavier initialization for weights\n",
    "        torch.nn.init.xavier_uniform_(self.model.fc.weight)\n",
    "        self.model.fc.bias.data.fill_(0.01)\n",
    "\n",
    "        # Make the weights of the last layer trainable\n",
    "        for param in self.model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        ## Use LogSoftmax activation for the output layer\n",
    "        #model.fc = nn.LogSoftmax(model.fc)\n",
    "\n",
    "        self.model.to(self.device) ## move the model to the device\n",
    "\n",
    "\n",
    "    def compute_accuracy(self,model,data_iterator):\n",
    "\n",
    "        \"\"\"\n",
    "        Method to compute the accuracy of the given model over the dataset in the data_iterator.\n",
    "\n",
    "        params:\n",
    "\n",
    "            model : The torch neural net model whose performance has to be measured.\n",
    "\n",
    "            data_iterator : The data iterator over which the computation of the metrics has to be done.\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            loss,accuracy of the \"model\" over the \"data_iterator\".\n",
    "        \"\"\"\n",
    "\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "\n",
    "        loss = 0\n",
    "        train_mode = model.training\n",
    "\n",
    "        # since we're testing, switch of train mode if it is on.\n",
    "        if train_mode:\n",
    "            model.eval()\n",
    "\n",
    "        with torch.no_grad(): ##don't compute gradients\n",
    "            for data in data_iterator:\n",
    "                images, labels = data\n",
    "                images, labels = images.to(self.device), labels.to(self.device) ## move the inputs and labels to the device\n",
    "\n",
    "                # calculate outputs by running images through the network\n",
    "                outputs = model(images)\n",
    "                loss += self.criterion(outputs, labels).item() * images.size(0) ## loss.item() is average loss of the batch, so multiply by batch size.\n",
    "\n",
    "                preds = torch.max(outputs.data, 1)[1]\n",
    "\n",
    "                total_preds += images.size(0)\n",
    "                correct_preds += (preds == labels).sum().item()\n",
    "\n",
    "        if train_mode: # if model was originally in train mode, switch it back to train mode.\n",
    "            model.train() ## switch back to train mode\n",
    "\n",
    "        #print(f'Accuracy of the model on the {len(data_iterator.dataset.samples)} test images: {round(100*correct/total,2)} %')\n",
    "\n",
    "        accuracy = round(100*correct_preds/total_preds,2)\n",
    "        loss = round(loss/total_preds,2)\n",
    "\n",
    "        return loss,accuracy\n",
    "\n",
    "    def train(self,lr,weight_decay,loss,optimiser,epochs):\n",
    "\n",
    "        \"\"\"\n",
    "        The method to perform the training, assuming model is already created using createResNet method.\n",
    "\n",
    "        Params:\n",
    "\n",
    "            lr : Learning rate\n",
    "            weight_decay : l2 regularization parameter.\n",
    "            loss : string, loss type. currently only \"crossentropy\" is supported\n",
    "            optimiser : \"adam\",\"nadam\",\"rmsprop\".\n",
    "            epochs : number of epochs to train.\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            None.\n",
    "        \"\"\"\n",
    "\n",
    "        ## specify the optimiser\n",
    "        if optimiser.lower() == \"adam\":\n",
    "            self.optimiser = optim.Adam(self.model.parameters(), lr=lr,weight_decay=weight_decay)\n",
    "\n",
    "        elif optimiser.lower() == \"nadam\":\n",
    "            self.optimiser = optim.NAdam(self.model.parameters(), lr=lr,weight_decay=weight_decay)\n",
    "\n",
    "        elif optimiser.lower() == \"rmsprop\":\n",
    "            self.optimiser = optim.RMSprop(self.model.parameters(), lr=lr,weight_decay=weight_decay)\n",
    "\n",
    "        ## Specify the loss criteria\n",
    "        if loss.lower() == \"crossentropy\":\n",
    "            self.criterion = nn.CrossEntropyLoss().to(self.device)\n",
    "\n",
    "\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        ## loop over the dataset multiple times\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "\n",
    "            correct_preds = 0\n",
    "            total = 0\n",
    "            count = 0\n",
    "            epoch_loss = 0.0\n",
    "\n",
    "\n",
    "            for i, data in enumerate(self.train_loader):\n",
    "\n",
    "                ## i is batch index\n",
    "\n",
    "                images, labels = data[0].to(self.device),data[1].to(self.device)  ## move the images and labels to the device.\n",
    "\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                self.optimiser.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                # logsoftmax is the output activation\n",
    "                outputs = F.log_softmax(self.model(images).to(self.device),dim=1)\n",
    "\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimiser.step()\n",
    "\n",
    "                epoch_loss +=  loss.item() * images.size(0) ## loss.item() is average loss of the batch, so multiply by batch size.\n",
    "\n",
    "                preds = torch.max(outputs.data, 1)[1]\n",
    "\n",
    "                total += images.size(0)\n",
    "                correct_preds += (preds == labels).sum().item()\n",
    "\n",
    "\n",
    "            train_accuracy = round(100*correct_preds/total,2)\n",
    "            train_loss = epoch_loss/total\n",
    "\n",
    "            val_loss,val_accuracy = self.compute_accuracy(self.model,self.val_loader)\n",
    "\n",
    "            if epoch%5 == 0:\n",
    "\n",
    "\n",
    "                if self.on_kaggle:\n",
    "                    torch.save(self.model, \"/kaggle/working/model\")\n",
    "                else:\n",
    "                    torch.save(self.model, \"Model\")\n",
    "\n",
    "\n",
    "            if epoch == 0:\n",
    "                print(f\"Samples in Train Data : {total}\")\n",
    "\n",
    "            if self.wandb_logging:\n",
    "\n",
    "                wandb.log({'train loss': train_loss, 'train accuracy': train_accuracy, 'Validation loss': val_loss, 'Validation accuracy': val_accuracy,'epoch': epoch+1})\n",
    "\n",
    "            print(f'Epoch : {epoch+1}\\t Train Accuracy : {train_accuracy:.2f}%\\t Train loss: {train_loss:.2f}\\t Validation Accuracy : {val_accuracy:.2f}%\\t Validation Loss : {val_loss:.2f}')\n",
    "            epoch_loss = 0.0\n",
    "\n",
    "        print('Finished Training!!')\n",
    "\n",
    "        end_time = time.time() - start_time\n",
    "        print(f\"Time Taken for Training: {round(end_time/60,2)}\")\n",
    "\n",
    "    def test_model(self):\n",
    "        \n",
    "        ## Compute and Report the test accuracy\n",
    "\n",
    "        test_loss,test_accuracy = self.compute_accuracy(self.model,self.test_loader)\n",
    "        print(f'Test Accuracy : {test_accuracy:.2f}%\\t Test loss: {test_loss:.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRqv3pDobONL"
   },
   "source": [
    "## Choosing ResNet50 as pre-trained model for finetuning.\n",
    "\n",
    "Because:\n",
    "\n",
    "1. The Identity connections used in the architecture is a really cool idea. Wanted to have some hands on on it.\n",
    "2. It has a really good accuracy on the ImageNet challenge, which means it is good at recognizing many species like shark etc. So hoping it would give a boost now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTOOWiwnbONL"
   },
   "source": [
    "### Addressing the issue of input image shape difference between ResNet and the Dataset.\n",
    "\n",
    "\n",
    "The inference transforms are available at ResNet50_Weights.IMAGENET1K_V2.transforms and perform the following preprocessing operations: Accepts PIL.Image, batched (B, C, H, W) and single (C, H, W) image torch.Tensor objects. The images are resized to resize_size=[232] using interpolation=InterpolationMode.BILINEAR, followed by a central crop of crop_size=[224]. Finally the values are first rescaled to [0.0, 1.0] and then normalized using mean=[0.485, 0.456, 0.406] and std=[0.229, 0.224, 0.225].\n",
    "\n",
    "\n",
    "Source : [https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet50.html#torchvision.models.resnet50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1712312334861,
     "user": {
      "displayName": "Tejasvi",
      "userId": "11432105167454296241"
     },
     "user_tz": -330
    },
    "id": "bHX2d-LubONL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1712312334861,
     "user": {
      "displayName": "Tejasvi",
      "userId": "11432105167454296241"
     },
     "user_tz": -330
    },
    "id": "rF1EuJ9UbONL",
    "outputId": "4432cb58-8274-406f-ba80-cf8069dd7336"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTo viz images after transform\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "To viz images after transform\n",
    "\"\"\"\n",
    "\n",
    "#plt.imshow(img[1].permute(1,2,0))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5142,
     "status": "ok",
     "timestamp": 1712312339999,
     "user": {
      "displayName": "Tejasvi",
      "userId": "11432105167454296241"
     },
     "user_tz": -330
    },
    "id": "nzi01-8IbONM",
    "outputId": "42140332-57f1-448a-b3c1-810a8cacfbf8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: b4vhucx5\n",
      "Sweep URL: https://wandb.ai/tmajestical/JV_CS23M036_TEJASVI_DL_ASSIGNMENT2/sweeps/b4vhucx5\n"
     ]
    }
   ],
   "source": [
    "wandb.login(key=\"\")\n",
    "\n",
    "\n",
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'name' : 'PA2 ResNet Fine Tuning',\n",
    "    'metric': {\n",
    "      'name': 'Validation accuracy',\n",
    "      'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "\n",
    "        'optimiser': {\n",
    "            'values': [\"adam\",\"rmsprop\",\"nadam\"]\n",
    "        },\n",
    "\n",
    "        'lr': {\n",
    "            'values': [1e-3,1e-4,3e-4]\n",
    "        },\n",
    "\n",
    "        'weight_decay': {\n",
    "            'values': [0]\n",
    "        },\n",
    "\n",
    "\n",
    "        'data_aug' : {\n",
    "\n",
    "            'values' : [None,1,2]\n",
    "        },\n",
    "\n",
    "        'epochs' : {\n",
    "\n",
    "            'values' : [3,5,8]\n",
    "        },\n",
    "\n",
    "        'batch_size':{\n",
    "            'values' : [16,32]\n",
    "        }\n",
    "        }\n",
    "\n",
    "        }\n",
    "sweep_id = wandb.sweep(sweep=sweep_config, project='JV_CS23M036_TEJASVI_DL_ASSIGNMENT2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1712312339999,
     "user": {
      "displayName": "Tejasvi",
      "userId": "11432105167454296241"
     },
     "user_tz": -330
    },
    "id": "Ts0fpIQ2bONM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1712312339999,
     "user": {
      "displayName": "Tejasvi",
      "userId": "11432105167454296241"
     },
     "user_tz": -330
    },
    "id": "GsTsXPyhbONM"
   },
   "outputs": [],
   "source": [
    "def setup_and_start_expt(config,wandb_log=False,data_dir = \"inaturalist_12K/\"):\n",
    "    ##using apple silicon GPU\n",
    "\n",
    "    wandb_logging = wandb_log\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    data_dir = \"inaturalist_12K/\"\n",
    "\n",
    "    print(f\"Using {device}\")\n",
    "\n",
    "    ## dataloader creation hyperparams:\n",
    "\n",
    "    batch_size = config['batch_size']\n",
    "    shuffle = True\n",
    "    num_workers = 2\n",
    "    pin_memory = False\n",
    "\n",
    "    #RandomSolarize(threshold=192.0)\n",
    "\n",
    "    if config['data_aug']:\n",
    "\n",
    "        train_data_augmentation_transforms1 = [transforms.RandomPerspective(p=1)] ## Random perspective transform\n",
    "        train_data_augmentation_transforms2 = [transforms.ColorJitter(brightness=.5, hue=.5)] ## colour jitter\n",
    "        #train_data_augmentation_transforms = [transforms.ElasticTransform()] ## this is good, but computationally extremely expensive\n",
    "\n",
    "        list_of_train_data_augmentation_transforms = [train_data_augmentation_transforms1,train_data_augmentation_transforms2]\n",
    "        list_of_train_data_augmentation_transforms = list_of_train_data_augmentation_transforms[:config['data_aug']]\n",
    "\n",
    "    else: ## if no data augmentation, train_loader returned would just be on the original dataset.\n",
    "\n",
    "        list_of_train_data_augmentation_transforms = []\n",
    "\n",
    "\n",
    "    ## create an experiment\n",
    "    experiment = Experiment(device=device,base_dir = base_data_dir, wandb_logging=False)\n",
    "\n",
    "     ## CNN Hyperparams\n",
    "    num_output_neurons =  10\n",
    "\n",
    "    ## create CNN model\n",
    "    experiment.createResNet(num_output_neurons)\n",
    "\n",
    "    ##create data loaders for train, validation and test datasets.\n",
    "    train_loader,val_loader,test_loader  = experiment.create_dataloaders(batch_size=batch_size,shuffle=shuffle,list_of_train_data_augmentation_transforms=list_of_train_data_augmentation_transforms,num_workers=num_workers,pin_memory=pin_memory)\n",
    "\n",
    "\n",
    "    ##training Hyper Params:\n",
    "\n",
    "    lr = config['lr']\n",
    "    weight_decay = config['weight_decay']\n",
    "    optimiser = config['optimiser']\n",
    "    epochs = config['epochs']\n",
    "    loss = \"crossentropy\"\n",
    "\n",
    "    experiment.train(lr = lr,weight_decay = weight_decay,loss = loss,optimiser = optimiser,epochs = epochs)\n",
    "\n",
    "    experiment.test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1712312339999,
     "user": {
      "displayName": "Tejasvi",
      "userId": "11432105167454296241"
     },
     "user_tz": -330
    },
    "id": "lNAlie2MbONM"
   },
   "outputs": [],
   "source": [
    "custom_config = {\n",
    "\n",
    "        'optimiser': \"adam\",\n",
    "\n",
    "        'lr' : 1e-3,\n",
    "\n",
    "        'weight_decay': 0,\n",
    "\n",
    "        'epochs' : 3,\n",
    "\n",
    "        'batch_size': 32,\n",
    "\n",
    "        'data_aug' : 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1712312339999,
     "user": {
      "displayName": "Tejasvi",
      "userId": "11432105167454296241"
     },
     "user_tz": -330
    },
    "id": "Trzng0aKbONM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps\n",
      "Preparing data from train/\n",
      "Preparing data from validation/\n",
      "Preparing data from test/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3dc939f389f449e8ffdea09e7d1264a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples in Train Data : 15998\n",
      "Epoch : 1\t Train Accuracy : 70.96%\t Train loss: 1.01\t Validation Accuracy : 81.30%\t Validation Loss : 0.68\n",
      "Epoch : 2\t Train Accuracy : 79.87%\t Train loss: 0.65\t Validation Accuracy : 82.55%\t Validation Loss : 0.62\n",
      "Epoch : 3\t Train Accuracy : 82.06%\t Train loss: 0.58\t Validation Accuracy : 83.70%\t Validation Loss : 0.57\n",
      "Finished Training!!\n",
      "Time Taken for Training: 5.95\n",
      "Test Accuracy : 83.70%\t Test loss: 0.51\n"
     ]
    }
   ],
   "source": [
    "setup_and_start_expt(custom_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1712312339999,
     "user": {
      "displayName": "Tejasvi",
      "userId": "11432105167454296241"
     },
     "user_tz": -330
    },
    "id": "CykK1F5hbONM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421,
     "referenced_widgets": [
      "c34245f28c44455a982c34591f0cb2cc",
      "4ea8d24d595f4f83b8cb7685013348c9",
      "65445633d844426b90da99f53c362a14",
      "3b2b6886ecfb47f488a994463939a351",
      "053c196af8014f7a815a140d18734621",
      "016d7ad6561a4ff19a770bc159c9bf5c",
      "d8468a92b5c246c8ab39ebe99166b797",
      "106d784f3808453f977c7b38cb04be52",
      "07b8e20a25db4fa3a965ba3b8700541b",
      "0b72273f915943168f470053718e8425",
      "dc9a8351b2cb4562ae1d7647c3f76bab"
     ]
    },
    "id": "bBIhu5h4bONN",
    "outputId": "6fcdc4b2-1583-4802-ee18-319ba3c4c675"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x93m02dq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_aug: None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimiser: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs23m036\u001b[0m (\u001b[33mtmajestical\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/drive/Othercomputers/My Mac/JV SEM2/JV Deep Learning/JV Assignments/JV-Deep-Learning-Assignment2/wandb/run-20240405_101902-x93m02dq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tmajestical/JV_CS23M036_TEJASVI_DL_ASSIGNMENT2/runs/x93m02dq' target=\"_blank\">misunderstood-sweep-1</a></strong> to <a href='https://wandb.ai/tmajestical/JV_CS23M036_TEJASVI_DL_ASSIGNMENT2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/tmajestical/JV_CS23M036_TEJASVI_DL_ASSIGNMENT2/sweeps/b4vhucx5' target=\"_blank\">https://wandb.ai/tmajestical/JV_CS23M036_TEJASVI_DL_ASSIGNMENT2/sweeps/b4vhucx5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tmajestical/JV_CS23M036_TEJASVI_DL_ASSIGNMENT2' target=\"_blank\">https://wandb.ai/tmajestical/JV_CS23M036_TEJASVI_DL_ASSIGNMENT2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/tmajestical/JV_CS23M036_TEJASVI_DL_ASSIGNMENT2/sweeps/b4vhucx5' target=\"_blank\">https://wandb.ai/tmajestical/JV_CS23M036_TEJASVI_DL_ASSIGNMENT2/sweeps/b4vhucx5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tmajestical/JV_CS23M036_TEJASVI_DL_ASSIGNMENT2/runs/x93m02dq' target=\"_blank\">https://wandb.ai/tmajestical/JV_CS23M036_TEJASVI_DL_ASSIGNMENT2/runs/x93m02dq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 131MB/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data from train/\n",
      "Preparing data from validation/\n",
      "Preparing data from test/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34245f28c44455a982c34591f0cb2cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    '''\n",
    "    WandB calls main function each time with differnet combination.\n",
    "\n",
    "    We can retrive the same and use the same values for our hypermeters.\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "    with wandb.init() as run:\n",
    "\n",
    "        run_name = \"-optim_\"+str(wandb.config.optimiser)+\"-lr_\"+str(wandb.config.lr)+\"-reg_\"+str(wandb.config.weight_decay)+\"-epochs_\"+str(wandb.config.epochs)+\"-data_aug\"+str(wandb.config.data_aug)\n",
    "\n",
    "        wandb.run.name=run_name\n",
    "\n",
    "        setup_and_start_expt(wandb.config,wandb_log = True,base_data_dir)\n",
    "\n",
    "\n",
    "wandb.agent(sweep_id, function=main,count=30) # calls main function for count number of times.\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iESWUG-tbONN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KADOBnEObONN"
   },
   "source": [
    "### References:\n",
    "\n",
    "1. https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet50.html#torchvision.models.resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LyjD91RzbONN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4675321,
     "sourceId": 7950185,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "016d7ad6561a4ff19a770bc159c9bf5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "053c196af8014f7a815a140d18734621": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07b8e20a25db4fa3a965ba3b8700541b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0b72273f915943168f470053718e8425": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "106d784f3808453f977c7b38cb04be52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b2b6886ecfb47f488a994463939a351": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b72273f915943168f470053718e8425",
      "placeholder": "​",
      "style": "IPY_MODEL_dc9a8351b2cb4562ae1d7647c3f76bab",
      "value": " 0/8 [00:00&lt;?, ?it/s]"
     }
    },
    "4ea8d24d595f4f83b8cb7685013348c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_016d7ad6561a4ff19a770bc159c9bf5c",
      "placeholder": "​",
      "style": "IPY_MODEL_d8468a92b5c246c8ab39ebe99166b797",
      "value": "  0%"
     }
    },
    "65445633d844426b90da99f53c362a14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_106d784f3808453f977c7b38cb04be52",
      "max": 8,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_07b8e20a25db4fa3a965ba3b8700541b",
      "value": 0
     }
    },
    "c34245f28c44455a982c34591f0cb2cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4ea8d24d595f4f83b8cb7685013348c9",
       "IPY_MODEL_65445633d844426b90da99f53c362a14",
       "IPY_MODEL_3b2b6886ecfb47f488a994463939a351"
      ],
      "layout": "IPY_MODEL_053c196af8014f7a815a140d18734621"
     }
    },
    "d8468a92b5c246c8ab39ebe99166b797": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc9a8351b2cb4562ae1d7647c3f76bab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
