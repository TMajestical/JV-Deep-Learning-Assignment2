{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bf5ab33-3dd0-4892-86d1-30a5b5647b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78650119-e33a-4460-a456-bfcc7ff99de4",
   "metadata": {},
   "source": [
    "I would develop the code for the assignment in this notebook as it is easy to quickly test (and even unit testing).\n",
    "\n",
    "When a module/part is bug free I would add it to the .py file later.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cf443ed0-08d3-4cb9-939e-0f89866253c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "88764d7a-de7d-4027-880e-9958a89230de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dir(dir,returnIfDirAlreadyExists=False):\n",
    "    \"\"\"\n",
    "    Function to create a directory, if it doesn't exist\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.mkdir(dir)\n",
    "    except Exception as e:\n",
    "        if \"File exists\" in str(e):\n",
    "            if returnIfDirAlreadyExists:\n",
    "                return True\n",
    "            pass\n",
    "        else:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f14a836f-817b-4317-9728-9629874d1841",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 76 #setting this as seed wherever randomness comes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7d5bac8d-ac8a-43a8-9eba-235fa5688183",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train data downloaded from the given source (https://storage.googleapis.com/wandb_datasets/nature_12K.zip)\n",
    "\n",
    "\"\"\"\n",
    "Now, the goal is to split 20% of train data, in \"train\" folder to get validation data.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "data_base_dir = 'inaturalist_12K/'\n",
    "\n",
    "def train_validation_split(base_dir,seed = 76):\n",
    "    \"\"\"\n",
    "    Function to split 20% of the train data into validation data, Uniformly At Random (UAR). Import os and shutil before using this method.\n",
    "\n",
    "    Note  : Instead of taking 20% of samples randomly out of the entire train data; 20% of train data of each class is taken (UAR), \n",
    "    so that for training there is a balance between the number of samples per class.\n",
    "\n",
    "    Params:\n",
    "\n",
    "        base_dir : The path to the directory in which the \"train/\" and \"test/\" directories are present after unzipping. It is assumed that the given dir path string has a \"/ at the end.\n",
    "\n",
    "        seed : The seed use in the random number generator, default : 76.\n",
    "\n",
    "    Returns :\n",
    "\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    base_data_dir = base_dir\n",
    "    train_base_dir = base_data_dir+'train/'\n",
    "    train_data_class_dirs = os.listdir(train_base_dir)\n",
    "    \n",
    "    ## remove dirs starting with \".\" from the list\n",
    "    train_data_class_dirs = [i for i in train_data_class_dirs if i[0] != \".\" ]\n",
    "\n",
    "    ## Test data is called as val, which is confusing, hence renaming it to test\n",
    "    os.rename(data_base_dir+\"val/\",base_data_dir+\"test/\")\n",
    "    \n",
    "    \n",
    "    ## validation dir\n",
    "    val_base_dir = base_data_dir+'validation/'\n",
    "    make_dir(val_base_dir)\n",
    "    \n",
    "    ## Iterate over each class and\n",
    "    ## take 20% data of each class at random as validation data\n",
    "    \n",
    "    random_num_generator = np.random.RandomState(seed)\n",
    "    \n",
    "    for class_label in train_data_class_dirs:\n",
    "    \n",
    "        current_class_train_filenames = os.listdir(train_base_dir+class_label+\"/\")\n",
    "    \n",
    "        num_of_files = len(current_class_train_filenames)\n",
    "        \n",
    "        validation_indices = random_num_generator.choice(num_of_files,int(0.2*num_of_files),replace=False)\n",
    "        train_indices = np.array(list(set(np.arange(num_of_files)).difference(set(validation_indices))))\n",
    "    \n",
    "        ##create class dir validation dir\n",
    "        cur_validation_dir = val_base_dir + class_label +\"/\"\n",
    "        make_dir(cur_validation_dir)\n",
    "        \n",
    "        for i in validation_indices:\n",
    "            shutil.move(train_base_dir+class_label+\"/\"+current_class_train_filenames[i],cur_validation_dir+current_class_train_filenames[i])\n",
    "        \n",
    "        print(f\"Validation Split for {class_label} is Done!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3c4e6c7c-450c-4a24-9936-d20fe7bcaf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Split for Plantae is Done!\n",
      "Validation Split for Aves is Done!\n",
      "Validation Split for Amphibia is Done!\n",
      "Validation Split for Insecta is Done!\n",
      "Validation Split for Animalia is Done!\n",
      "Validation Split for Mollusca is Done!\n",
      "Validation Split for Fungi is Done!\n",
      "Validation Split for Arachnida is Done!\n",
      "Validation Split for Reptilia is Done!\n",
      "Validation Split for Mammalia is Done!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Careful perform this train-validation split only once in the entire lifetime, that too on the unzipped dataset.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "base_data_dir = \"inaturalist_12K/\"\n",
    "\n",
    "#train_validation_split(base_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b7aa94bc-98ae-4cf9-8d68-0c445f51ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Create loader for train, test and validation data \"\"\"\n",
    "\n",
    "## Train data\n",
    "train_path = base_data_dir+\"train/\"\n",
    "train_dataset = torchvision.datasets.ImageFolder(root=train_path,transform=torchvision.transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=16,shuffle=True,num_workers=0)\n",
    "\n",
    "## Validation data\n",
    "val_path = base_data_dir+\"validation/\"\n",
    "val_dataset = torchvision.datasets.ImageFolder(root=val_path,transform=torchvision.transforms.ToTensor())\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,batch_size=16,shuffle=True,num_workers=0)\n",
    "\n",
    "## Test data\n",
    "test_path = base_data_dir+\"test/\"\n",
    "test_dataset = torchvision.datasets.ImageFolder(root=test_path,transform=torchvision.transforms.ToTensor())\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=16,shuffle=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed26168-a782-4dca-ba95-e49bd4ddecbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59d10f3-ca68-494f-a842-540a25e4e94f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb8182f8-b5cf-45ba-bf1f-5e2f61f8e8f3",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "1. https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "2. https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#:~:text=PyTorch%20provides%20two%20data%20primitives,easy%20access%20to%20the%20samples.\n",
    "3. https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2fa0fb-c54e-45f6-ad67-e09765be08c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
